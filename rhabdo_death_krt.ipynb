{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jomericer/rhabdo_death_krt/blob/main/rhabdo_death_krt_datashare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Init**"
      ],
      "metadata": {
        "id": "XE9MnI6nNLEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade shap\n",
        "\n",
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib.pylab import rcParams\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_score, recall_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_recall_curve\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# load datasets\n",
        "df_e = pd.read_csv('/df_e.csv')\n",
        "df_m = pd.read_csv('/df_e.csv')\n",
        "df_c = pd.read_csv('/df_e.csv')\n",
        "print('datasets loaded')\n",
        "\n",
        "# setup inputs and output\n",
        "invars = ['age','aniongap','bicarbonate','urea','calcium','sodium','chloride','creatinine','potassium','phosphate','ck',\n",
        "       'hematocrit','sex_F','ethnicity_white','wbc','platelet']\n",
        "outvar = 'composite_rrt_death' # either composite_rrt_death or aki_7d_cr\n",
        "print(f\"total features: {len(invars)};  output = {outvar}\\n{invars}\")\n",
        "\n",
        "# determine amount of class imbalance\n",
        "db=['mimic','eicu','combined']\n",
        "avg=[0]*3\n",
        "for i, df_ in enumerate([df_m, df_e, df_c]):\n",
        "  len_=df_.shape[0]\n",
        "  pos=sum(df_[outvar])\n",
        "  neg=len_-pos\n",
        "  avg[i]=neg/pos\n",
        "  print(f'{db[i]}: len={len_}, pos(1)={pos}, neg(0)={neg} => {pos/(len_)*100:.2f}%, scale_pos_weight={neg/pos:.2f}')\n",
        "print(f'avg scale_pos_weight={np.mean(avg):.2f}')\n",
        "\n",
        "# generate train and test datasets\n",
        "split = 0.3\n",
        "RAND = 15\n",
        "folds = 3\n",
        "m1_df = df_e # train/test dataset\n",
        "val = df_m # validate dataset\n",
        "X = m1_df.loc[:,invars].copy()\n",
        "y = m1_df[outvar].copy().fillna(0)\n",
        "X__test = val.loc[:,invars].copy()\n",
        "y__test = val[outvar].copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, stratify=y, random_state=RAND)\n",
        "print(f\"\\ntotal features: {len(invars)};  output = {outvar} -> total 1's = {y.sum()} ({y.sum()/len(y)*100:.1f}%)\\ntrain size = {1-split}, test size = {split}\")\n",
        "print(\"Train and Test datasets created\")\n"
      ],
      "metadata": {
        "id": "3goO0DSnNSTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML model**"
      ],
      "metadata": {
        "id": "FfXC2js3bQYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(\n",
        "    n_estimators=60,\n",
        "    criterion='entropy',\n",
        "    max_depth=4,\n",
        "    min_samples_split=5,\n",
        "    class_weight=\"balanced_subsample\",\n",
        "    ccp_alpha=0.016634211826061396,\n",
        "    max_samples=None,\n",
        "    verbose=0)\n",
        "\n",
        "print(f\"Performing CV with {folds}-folds...\")\n",
        "cv_scores = cross_validate(rfc, X_train, y_train,\n",
        "                           scoring=['accuracy','roc_auc','neg_log_loss'],\n",
        "                           cv=StratifiedKFold(folds), return_train_score=True, verbose=0)\n",
        "print(f\"CV using Stratified Kfold strategy:\\n \\\n",
        "Train accuracy: {np.mean(cv_scores['train_accuracy']):.4f}, ({np.std(cv_scores['train_accuracy']):.4f}) \\n \\\n",
        " Test accuracy: {np.mean(cv_scores['test_accuracy']):.4f}, ({np.std(cv_scores['test_accuracy']):.4f}) \\n \\\n",
        "Train AUC: {np.mean(cv_scores['train_roc_auc']):.4f}, ({np.std(cv_scores['train_roc_auc']):.4f}) \\n \\\n",
        " Test AUC: {np.mean(cv_scores['test_roc_auc']):.4f}, ({np.std(cv_scores['test_roc_auc']):.4f}) \\n \\\n",
        "Train logloss: {np.mean(cv_scores['train_neg_log_loss']):.4f}, ({np.std(cv_scores['train_neg_log_loss']):.4f}) \\n \\\n",
        " Test logloss: {np.mean(cv_scores['test_neg_log_loss']):.4f}, ({np.std(cv_scores['test_neg_log_loss']):.4f}) \")\n",
        "\n",
        "# fit model\n",
        "rfc.fit(X_train, y_train)\n",
        "train_pred = rfc.predict(X_train)\n",
        "train_prob = rfc.predict_proba(X_train)[:,1]\n",
        "test_pred = rfc.predict(X_test)\n",
        "test_prob = rfc.predict_proba(X_test)[:,1]\n",
        "val_pred = rfc.predict(X__test)\n",
        "val_prob = rfc.predict_proba(X__test)[:,1]\n",
        "\n",
        "# Metrics\n",
        "fpr_m, tpr_m, thr = roc_curve(comb_df_imp[outvar], comb_df_imp['mcmahon'])\n",
        "optimal_idx = np.argmax(tpr_m - fpr_m)\n",
        "AUCm  = auc(fpr_m, tpr_m)\n",
        "\n",
        "print(f\"\\n{'FINAL TRAINED MODEL':26} {'train':10} | {'test':10} | {'validate':10} | mcmahon {thr[optimal_idx]}\")\n",
        "print(f\" {'Accuracy:':25} {accuracy_score(y_train, train_pred):10.4f} | \" \\\n",
        "      f\"{accuracy_score(y_test, test_pred):10.4f} | \" \\\n",
        "      f\"{accuracy_score(y__test, val_pred):10.4f} |\")\n",
        "print(f\" {'Precision Score:':25} {precision_score(y_train, train_pred):10.4f} | \" \\\n",
        "      f\"{precision_score(y_test, test_pred):10.4f} | \" \\\n",
        "      f\"{precision_score(y__test, val_pred):10.4f} | \")\n",
        "print(f\" {'Recall (sensitivity):':25} {recall_score(y_train, train_pred):10.4f} | \" \\\n",
        "      f\"{recall_score(y_test, test_pred):10.4f} | \" \\\n",
        "      f\"{recall_score(y__test, val_pred):10.4f} | {tpr_m[optimal_idx]:10.4f}\")\n",
        "print(f\" {'AUC Score:':25} {roc_auc_score(y_train, train_prob):10.4f} | \" \\\n",
        "      f\"{roc_auc_score(y_test, test_prob):10.4f} | \" \\\n",
        "      f\"{roc_auc_score(y__test, val_prob):10.4f} | {AUCm:10.4f}\")\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_train, train_prob)\n",
        "AUC_ = auc(fpr, tpr)\n",
        "fprt, tprt, _ = roc_curve(y_test, test_prob)\n",
        "AUCt = auc(fprt, tprt)\n",
        "fprv, tprv, _ = roc_curve(y__test, val_prob)\n",
        "AUCv = auc(fprv, tprv)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Train = %0.4f' % AUC_)\n",
        "plt.plot(fprt, tprt, label='Test = %0.4f' % AUCt)\n",
        "plt.plot(fprv, tprv, label='Validate = %0.4f' % AUCv)\n",
        "plt.plot(fpr_m, tpr_m, label='McMahon = %0.4f' % AUCm)\n",
        "plt.plot([0, 1], [0, 1], 'k--') # 0.5 line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('1 - Specificity')\n",
        "plt.ylabel('Sensitivity')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# SHAP summary plot\n",
        "explainer = shap.TreeExplainer(rfc)\n",
        "shap_values = explainer.shap_values(X)\n",
        "shap.summary_plot(shap_values[1], X_full, color='white', max_display=X_full.shape[1])"
      ],
      "metadata": {
        "id": "MMxCX4UpbMTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHAP**"
      ],
      "metadata": {
        "id": "ZUz0Gab1cPJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP summary plot\n",
        "explainer = shap.TreeExplainer(rfc)\n",
        "shap_values = explainer.shap_values(X)\n",
        "shap.summary_plot(shap_values[1], X, color='white', max_display=X.shape[1])\n",
        "\n",
        "# SHAP partial dependence\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14,10))\n",
        "shap.dependence_plot('creatinine', shap_values[1], X, interaction_index=None, ax=axes[0,0], show=False)\n",
        "shap.dependence_plot('phosphate', shap_values[1], X, interaction_index=None, ax=axes[0,1], show=False)\n",
        "shap.dependence_plot('platelet', shap_values[1], X, interaction_index=None, ax=axes[1,0], show=False)\n",
        "shap.dependence_plot('urea', shap_values[1], X, interaction_index=None, ax=axes[1,1], show=False)\n",
        "fig.subplots_adjust(wspace=0.25)\n",
        "plt.show()\n",
        "\n",
        "# SHAP force plots\n",
        "arr=[]\n",
        "arr=[0 for i in range(16)]\n",
        "ddf = pd.DataFrame([[0]*16]*len(X), index=list(range(0,len(X))), columns=X.columns)\n",
        "\n",
        "for i in list(range(211,219)):\n",
        "  print(f\"for ID = {i}:\")\n",
        "  # round values for increased palatability\n",
        "  arr[0]=int(X.iloc[i,0]) # age\n",
        "  arr[1]=int(np.round(X.iloc[i,1],0)) # AG\n",
        "  arr[2]=int(np.round(X.iloc[i,2],0)) # hco3\n",
        "  arr[3]=np.round(X.iloc[i,3],2) # ur\n",
        "  arr[4]=np.round(X.iloc[i,4],2) # ca\n",
        "  arr[5]=int(np.round(X.iloc[i,5],0)) # na\n",
        "  arr[6]=int(np.round(X.iloc[i,6],0)) # cl\n",
        "  arr[7]=int(np.round(X.iloc[i,7],0)) # cr\n",
        "  arr[8]=np.round(X.iloc[i,8],2) # k\n",
        "  arr[9]=np.round(X.iloc[i,9],2) # po4\n",
        "  arr[10]=int(np.round(X.iloc[i,10],0)) # ck\n",
        "  arr[11]=np.round(X.iloc[i,11],1) # hct\n",
        "  arr[12]=int(X.iloc[i,12]) # sex F\n",
        "  arr[13]=int(X.iloc[i,13]) # ehtn white\n",
        "  arr[14]=np.round(X.iloc[i,14],1) # wbc\n",
        "  arr[15]=int(np.round(X.iloc[i,15],0)) # plt\n",
        "  ddf.iloc[i] = arr\n",
        "  shap.force_plot(explainer.expected_value, shap_values[1][i], ddf.iloc[i], matplotlib = True)"
      ],
      "metadata": {
        "id": "Od0GT3AWcOnC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
